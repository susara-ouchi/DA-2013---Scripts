{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad5482e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04dc74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Connection.close()>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b66cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Simulate Source 1: SQLite Customer Database\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Insert random customers\n",
    "names = ['Alice', 'Bob', 'Charlie', 'Diana', 'Ethan', 'Fiona', 'George', 'Hannah', 'Ivan', 'Julia']\n",
    "countries = ['USA', 'UK', 'Canada', 'Germany', 'France', 'Australia']\n",
    "\n",
    "customers_data = [(i+1,\n",
    "                   random.choice(names) + str(i+1),\n",
    "                   random.randint(18, 65),\n",
    "                   random.choice(countries)) for i in range(120)]\n",
    "\n",
    "cursor.executemany(\"INSERT INTO customers VALUES (?, ?, ?, ?)\", customers_data)\n",
    "conn.commit()\n",
    "\n",
    "# Load customers into DataFrame\n",
    "df_customers = pd.read_sql_query(\"SELECT * FROM customers\", conn)\n",
    "print(\"SQLite Customers Table:\")\n",
    "print(df_customers.head(), \"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Simulate Source 2: CSV File with Transactions\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Create random transactions for these customers\n",
    "transaction_data = {\n",
    "    'transaction_id': range(1, 301),\n",
    "    'customer_id': np.random.randint(1, 121, 300),\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Headphones', 'Camera', 'Tablet'], 300),\n",
    "    'amount': np.random.randint(50, 1200, 300),\n",
    "    'date': pd.date_range('2025-01-01', periods=300, freq='D')\n",
    "}\n",
    "\n",
    "df_transactions = pd.DataFrame(transaction_data)\n",
    "df_transactions.to_csv('transactions.csv', index=False)\n",
    "\n",
    "print(\"CSV Transactions Sample:\")\n",
    "print(df_transactions.head(), \"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Simulate Source 3: JSON File with Feedback\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "feedback_data = []\n",
    "for cid in range(1, 121):\n",
    "    feedback_data.append({\n",
    "        \"custID\": cid,\n",
    "        \"rating\": random.choice([1, 2, 3, 4, 5]),\n",
    "        \"feedback\": random.choice([\n",
    "            \"Excellent service\", \"Good experience\", \"Average\",\n",
    "            \"Delivery was late\", \"Product quality issue\"\n",
    "        ])\n",
    "    })\n",
    "\n",
    "with open('feedback.json', 'w') as f:\n",
    "    json.dump(feedback_data, f, indent=4)\n",
    "\n",
    "# Read JSON file into DataFrame\n",
    "with open('feedback.json') as f:\n",
    "    data = json.load(f)\n",
    "df_feedback = pd.DataFrame(data)\n",
    "\n",
    "print(\"JSON Feedback Sample:\")\n",
    "print(df_feedback.head(), \"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4. Integration Process (ETL)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Step 1: Extract (already loaded)\n",
    "# Step 2: Transform (clean and align column names)\n",
    "\n",
    "df_feedback.rename(columns={'custID': 'customer_id'}, inplace=True)\n",
    "\n",
    "# Step 3: Merge all sources\n",
    "df_merged = (\n",
    "    df_customers\n",
    "    .merge(df_transactions, on='customer_id', how='left')\n",
    "    .merge(df_feedback, on='customer_id', how='left')\n",
    ")\n",
    "\n",
    "# Step 4: Clean and handle missing values\n",
    "df_merged['feedback'] = df_merged['feedback'].fillna('No feedback')\n",
    "df_merged['rating'] = df_merged['rating'].fillna(0).astype(int)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5. Load Unified Data into SQLite\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "df_merged.to_sql('unified_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Unified Data (first few rows):\")\n",
    "print(df_merged.head(), \"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6. Example Queries for Insights\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "query1 = \"\"\"\n",
    "SELECT country, COUNT(DISTINCT customer_id) as num_customers,\n",
    "       ROUND(AVG(amount),2) as avg_spent\n",
    "FROM unified_data\n",
    "GROUP BY country\n",
    "ORDER BY avg_spent DESC\n",
    "\"\"\"\n",
    "print(\"Average Spending by Country:\")\n",
    "print(pd.read_sql_query(query1, conn), \"\\n\")\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT rating, COUNT(*) as num_feedbacks,\n",
    "       ROUND(AVG(amount),2) as avg_amount\n",
    "FROM unified_data\n",
    "GROUP BY rating\n",
    "ORDER BY rating DESC\n",
    "\"\"\"\n",
    "print(\"Customer Ratings vs Average Transaction Amount:\")\n",
    "print(pd.read_sql_query(query2, conn), \"\\n\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 7. Optional: Export Integrated Dataset\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "df_merged.to_csv('unified_dataset.csv', index=False)\n",
    "print(\"Integrated dataset exported to unified_dataset.csv\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Close the connection\n",
    "# -----------------------------------------------------------\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
